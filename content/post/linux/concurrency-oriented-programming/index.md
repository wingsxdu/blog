---
title: "浅析面向并发编程 · Analyze"
author: "beihai"
description: "面向并发编程"
summary: "<blockquote><p>并发这个概念由来已久，其主要思想是使多个任务可以在同一个时间段内下执行以便更快地得到结果。最早支持并发编程的语言是汇编语言，不过那时并没有任何的理论基础来支持这种编程方式，一个细微的编程错误就可能使程序变得非常不稳定，而且对程序的测试也几乎是不可能的。随着计算机软硬件技术的发展，如今并发程序的编写早已没有以前那么复杂。在今天可以毫不夸张地说，如果我们想真正理解一门编程语言以及领悟怎样才能编好程序，学习并发编程这一步必不可少。</p></blockquote>"
tags: [
    "Analyze",
    "Linux",
    "并发编程",
    "多进程",
    "多线程",
    "同步",
]
categories: [
    "Analyze",
	"并发编程",
]
date: 2019-12-04T12:23:23+08:00
draft: false
---
> *原理分析（Analyze The Principles）是一系列对计算机科学领域中的程序设计进行分析，每一篇文章都会着重于某一个实际问题。如果你有想了解的问题、错误指正，可以在文章下面留言。* 

并发这个概念由来已久，其主要思想是使多个任务可以在同一个时间段内下执行以便更快地得到结果。最早支持并发编程的语言是汇编语言，不过那时并没有任何的理论基础来支持这种编程方式，一个细微的编程错误就可能使程序变得非常不稳定，而且对程序的测试也几乎是不可能的。随着计算机软硬件技术的发展，如今并发程序的编写早已没有以前那么复杂。在今天可以毫不夸张地说，如果我们想真正理解一门编程语言以及领悟怎样才能编好程序，学习并发编程这一步必不可少。

## 概述

并发编程的思想来自于多任务操作系统，在早期的单用户操作系统中，任务是一个接一个运行的，各个任务的执行完全是串行的，只有在一个任务运行完成后，另一个任务才会被读取。而多任务操作系统则允许终端用户同时运行多个程序。当一个程序暂时不需要使用 CPU 的时候，比如等待一个网络连接，系统内核会把该程序挂起或中断，使得其他程序可以使用 CPU。

并发编程是非常广泛的概念，其向下依赖于操作系统、数据存储等，中间层则由分布式系统、微服务等构建，而又具体落地于 Java 并发编程、Go 并发编程、JavaScript 异步编程等领域。本文将从多进程编程与多线程编程两个方面分析并发编程的实际原理。在此之前，需要介绍几个概念。

![type](index.assets/type.png)

#### 串行程序与并发程序

串行（Serial）程序特指只能被顺序指令执行的指令列表，并发程序则是可以被并发执行的多个串行程序的综合体。串行程序中的所有代码的先后顺序是固定的，而并发程序中只有部分代码是有序的，其中一些代码的执行顺序并没有明确指定，这一特性被称为不确定性，这导致并发程序即使在输入相同数据的情况下，每次代码的执行路径都是不同的。

并发程序允许其中的串行程序运行在一个或多个可共享的 CPU 之上，同时也允许每个串行程序都运行在专为它服务的 CPU 上。前一种方式也成为多元程序，它由操作系统内核支持并提供多个串行程序复用多个 CPU 的方法。多元处理时计算机的多个 CPU 共用一个存储器（内存），并且在同一时刻可能会有数个串行程序分别运行在不同的 CPU 之上。多元程序和多元处理是串行程序得以并发和并行运行的基础。

#### 并发程序与并行程序

在一些参考文献和图书中，常常将并发和并行的概念混淆。实际上两者之间有明显的区别。**并行是指物理上（计算机并行硬件，如多核 CPU）同时执行，并发指能够让多个任务在逻辑上交织执行的程序设计**。并发程序是一个比较宽泛的概念，代表了所有可以实现并发行为的程序，其中包含了并行程序。

#### 并发程序内部的交互

并发程序内部会被划分为多个部分（或代码段），每个部分可以看作一个串行程序。在这些串行程序之间，可能会存在交互需求。比如，多个串行程序可能都要对一个共享资源进行访问，或者相互传递一些数据。这种情况下，我们需要协调程序的执行，即**同步**（Synchronous）。同步的作用是避免在并发访问共享资源时可能发生的冲突，以及确保有条不紊地传递数据。

![inter-application-communication](index.assets/inter-application-communication.png)

根据同步的原则，程序如果想要使用一个共享资源，就必须先请求该资源并获取它的访问权。当程序不再需要某个资源的时候，该程序需放弃对资源的访问权（释放资源）。在同一时刻，某个资源应该只被一个程序占用，一个程序对资源的请求不应该导致其他正在访问该资源的程序中断，而应该等到占用程序释放资源后再请求。

数据传递也称为并发程序内部的通信，除同步外，我们也可以利用**异步**的方式对通信进行管理，这种方式使得数据可以不加延迟地发送给数据接收方。如果数据接收方还没有为接收数据做好准备，也不会造成数据接收方的等待，数据会被临时存储在通信缓存中。通信缓存是一种特殊的共享资源，可以同时被多个程序使用，数据接收方可以在准备就绪后按照先进先出进行接收。

## 进程的设计

进程是 Unix 及其衍生操作系统的根本，是资源分配的最小单位，所有的代码都在进程中执行。程序是存放在磁盘上、处于某个目录下的一个可执行文件，它是静态的实体，没有执行的含义。进程由程序执行得来，即进程是程序的实例，是一个动态的实体，有自己的生命周期。

#### 进程的衍生

进程使用`fork`（系统调用函数）能够创建若干个新的进程，前者称为父进程，后者成为子进程。每个子进程都是父进程的一个副本，拥有父进程的数据段、堆和栈的副本，并于父进程共享代码段。每一个子进程都是独立的，子进程对属于它的副本的修改对父进程和兄弟进程都是不可见的。为提高创建进程发的效率，Linux 系统内核使用写时复制（Copy on Write，简写 COW）等技术来对数据复制。也可通过系统调用`exec`切换子进程中的执行程序，替换其从父进程复制过来的代码段与数据段。

![process-fork](index.assets/process-fork.png)

Linux 系统下每一个进程都有父进程，所有进程形成了一个树形结构。当系统启动时，会建立一个 **init 进程**（ID 为 1），其它的进程都是 init 进程通过 fork 建立的。init 进程的父进程为它自己。如果某一个进程先于它的子进程结束，那么它的子进程将会被 init 进程“收养”，成为 init 进程的直接子进程。

#### 进程描述符与进程标识

为了管理进程，内核会对每个进程的属性和行为进行详细的描述，包括进程的优先级、状态、虚拟地址、访问权限等等，这些信息会被记录在每个进程的进程描述符（TASK_STRUCK）中。进程描述符是一个非常复杂的数据结构，其中也保存了进程在操作系统中的唯一标识：进程 ID（ProcessID，简称 PID）。PID 是一个非负整数且顺序编号，新创建的 PID 为前一个 PID 递增的结果。当 PID 达到最大限值时（Linux 下默认 32768），内核会从头开始查找闲置的进程 ID 并使用最先找到的值。进程描述符也包含了当前进程的父进程 ID（PPID），依此可以查询该进程的衍生过程。

可以利用编程语言查看当前进程 PID 和 PPID：

```go
pid := os.Getpid()
ppid := os.Getppid()
```

需要注意的是，PID 只是一个用来唯一标识进程的数字，并不传达与进程有关的任何信息。但系统内核可以高效地把 PID 转换成对应进程的描述符。我们可以用 shell 命令`kill`终止某个进程，或通过 PID 找到对应的进程向其发送信息。

#### 进程的状态

Linux 系统中，进程每个时刻都是有状态的，其可能的状态通常为以下七种：可执行状态、可中断的睡眠状态、不可中断的睡眠状态、暂停状态或跟踪状态、僵尸状态、退出状态。进程状态可以通过 shell 指令`ps aux`查看。

![task-state](index.assets/task-state.png)

- **可执行状态（TASK_RUNNING），简称 R**。处于该状态的进程表明它立刻要或正在 CPU 上运行。 进程调度器的任务就是从各个CPU的可执行队列中分别选择一个进程在该CPU上运行。
- **可中断的睡眠状态（TASK_INTERRUPTIBLE），简称 S**。处于这个状态的进程因为等待某事件的发生（比如等待 Socket 连接、信号量）而被挂起。这些进程会被放入对应事件的等待队列中。当事件发生时，对应的等待队列中的一个或多个进程将被唤醒。
- **不可中断的睡眠状态（TASK_UNINTERRUPTIBLE），简称 D**。与 S 状态类似，进程处于睡眠状态，但是此刻进程是不可中断的。不可中断，指的并不是CPU不响应外部硬件的中断，而是指进程不响应异步信号，比如无法用 kill 杀掉处于 D 状态的进程。处于 D 状态的进程通常是在等待 IO，比如磁盘 IO，网络 IO。
- **暂停状态或跟踪状态（TASK_STOPPED 或 TASK_TRACED），简称 T**。 向进程发送一个`SIGSTOP`信号，它就会因响应该信号而进入`TASK_STOPPED`状态，除非该进程本身处于D状态而不响应信号。向处于`TASK_STOPPED`状态的进程发送一个`SIGCONT`信号，可以让其从 T 状态恢复到 R 状态。处于`TASK_TRACED`状态的进程会暂停，并等待它的跟踪进程对它进行操作。例如使用 GDB 调试工具设置一个断点，进程运行到该断点处就会停下来。此时该进程处于跟踪状态。向处于跟踪状态的进程发送`SIGSTOP`信号不能使其恢复，只有当调试进程（跟踪进程）进行相应的系统调用调用或退出后才能恢复。
- **僵尸状态（TASK_DEAD - EXIT_ZOMBIE），简称 Z**。处于这个状态的进程在退出的过程中，除了进程描述符、退出码等少数信息以外，进程占有的绝大多数资源将被回收。保留这些信息是考虑到该进程的父进程可能需要它们。此时进程就只剩下 TASK_STRUCK 空壳，故称为僵尸进程。
- **退出状态（TASK_DEAD - EXIT_DEAD），简称 X**。处于这个状态的进程所有资源将会被操作系统回收，干净利落地被结束掉。

一个进程在其生命周期内可能会产生一系列状态转换，示意简图如下：

![task-state – switch](index.assets/task-state%20%E2%80%93%20switch.png)

注：进程状态转换的实际情况很复杂，为便于理解，上图只画出概要过程。

#### 地址空间与内存布局

当我们创建一个进程时，操作系统会为进程分配内存空间，该内存区域内的每一个单元地址都由指针来标识定位，即内存寻址。指针是一个正整数，由若干个二进制位表示，其长度由 CPU 字长决定，32 位计算机下为 2<sup>32</sup>，64 位计算机下为 2<sup>64</sup>。显然，一个进程不可能占有如此多的内存资源。这是因为上面提到的地址并非物理内存中的真实地址，而是虚拟地址。由虚拟地址标识的内存区域为虚拟地址空间，也就是常说的虚拟内存。

系统内核会为进程分配虚拟内存而不是物理内存，内核会将虚拟内存分为用户空间与内核空间两部分，用户空间占据地址的低部分，大小为 0 到 TASK_SIZE（TASK_SIZE 是一个常数，其值与具体的硬件平台相关）剩下的部分则为内核空间。划分情况如图所示：

![virtual-memory](index.assets/virtual-memory.png)

> 一些参考资料里认为一个进程拥有 4G  的地址空间，其中 1G 为内核空间，剩余 3G 为用户空间，并不是准确的说法。

其中内核空间由内核专用，用户进程的虚拟内存会被分配到用户空间中，通常情况下这些用户进程的虚拟内存之间相互独立，彼此不可见。进程的虚拟内存又会被内核划分为若干**页**（page），而物理内存的划分由 CPU 负责，一个物理内存单元被称为**页框**（page frame）。不同进程的页会被映射到不同的物理内存之上。如下图所示：

![page-and-page-frame](index.assets/page-and-page-frame.png)

在上图中，页框 5 被进程 A、B 共享使用，形成共享内存区，这也是 IPC 中共享内存方式的实现原理。而图中没有被映射到物理内存上的页，表示该页没有数据或未被使用，也可能是该页被换出磁盘的 swap 分区。

#### 系统调用

用户进程生存在用户空间中无法直接操控计算机的硬件，但是系统内核却可以。因此内核会暴露一些接口供用户进程调用，这是用户进程使用内核功能、操控硬件的唯一方式。用户进程使用内核接口的行为被称为系统调用（**动词**），但很多时候“系统调用”（**名词**）也代指内核提供的一系列接口。发生系统调用时，用户进程会先向内核空间发出一个明确的请求，并导致内核空间中数据的存取和指令的执行。

为了保证操作系统的安全和稳定，内核依据由 CPU 提供的、可以让进程驻留的特权级别建立了两个状态：**内核态**与**用户态**。CPU 在大部分时间里都处于用户态，此时的用户进程无法与内核接触。当用户进程发出一个系统调用时，内核把 CPU 从用户态切换到内核态，然后再执行对应的内核函数，执行结束后再把 CPU 切换回用户态并返回执行结果。

![syscall](index.assets/syscall.png)

这样设计的初衷就是：**给不同的操作给予不同的“权限”**，以确保系统的安全性。

#### 上下文切换

分时操作系统可以凭借 CPU 的威力快速地在多个进程间进行切换，被称为上下文（Context）切换，以此产生多个进程同时运行的假象。但是无论切换速度快慢，同一时刻正在运行的进程只会有一个，而每个进程都认为自己独占了 CPU。

上下文切换需要付出一定代价。如果要换下正在 CPU 上运行的进程 A，内核需要及时保存 A 的运行状态，同时如果被换上的进程 B 不是第一次运行，内核也要及时恢复 B 的上次运行状态。除此之外，内核还要负责进程的调度，在切换时运行那个进程、何时切换、何时再换上被换下的进程。

## 同步问题

在很多时候，我们需要多个进程之间相互配合完成一个任务。上文提到过，进程的用户空间是互相独立的，一般而言是不能互相访问的，唯一的例外是共享内存区。但在共享数据的过程中，可能会产生一些“干扰”。

> 不论是多 CPU、多进程还是多线程，只要它们之间存在数据共享，就一定会牵扯同步问题。

#### 计数器

**同步**是一个具有普遍意义的问题，为了更好地切入同步问题，我们举一个计数器例子进行说明。假设进程 A 创建一个计数器 Count，初值为 1，Count 与进程 B 共享，进程 A 与 B 并发执行相同的任务： 从数据库中查询符合条件的数据，并写入 ./temp 文件中。任务流程大致如下：

1. 从计数器中读取值；
2. 每次从数据库中查询一万条数据，若用 a 代表计数器值，那么查询范围为：[a, a+10000)；
3. 遍历查询数据，将符合条件的数据组成新的数据集合
4. 将数据集合写入 ./temp 文件；
5. 计数器的值加 10000，即 c = c+10000；
6. 检查数据是否全部读完，若是则程序退出，否则重复上述步骤；

**注：假设上面的例子运行在单个逻辑处理器上，多核处理器的进程调度可能略有不同。**

进程 A 和 B每次对指定数据集合迁移时，都要完成上面的六个步骤，但由于内核会对进程进行切换与调度，我们无法确保进程在一次循环查询过程不会被打断。在实际运行过程中，进程 A 与 B 可能会穿插在一起执行（基本上一定是穿插执行），而且上下文切换的粒度会比上面的描述步骤小很多。但为了清晰起见，我们可以假设一种可能的进程调度过程。

1. 内核使 CPU 运行进程 A，初始化计数器；
2. 进程 A 读取计数器初值 1；
3. CPU 被进程 B 抢占，读取计数器初值 1，并依此查询筛选数据，得到一个新的数据集合，此时内核认为进程 B 已经运行足够长的时间，将 A 换上 CPU；
4. 进程 A 开始查询并筛选数据，得到一个数据集合，这个数据集合与进程 B 完全一致；
5. 进程 A 将数据集合写入 ./temp 文件；
6. 进程 A 将计数器的值更新为 10001；
7. 内核把进程 A 换下，让 CPU 运行 B；
8. 进程 B 数据集合写入 ./temp 文件；
9. 进程 B 将计数器的值更新为 10001；

该进程调度过程如下图所示：

![count](index.assets/count.png)

通过示例图我们看出一个很明显的问题，进程 A 与 B 在做重复的事情，造成了双倍的资源消耗，却得到了一样的结果。这是由于同一个进程对计数器值的存取时间跨度太大了，计数器只达成了记录任务进度的目的，却没有对多进程进行任务协调，导致进程的执行过程完全是随机的。

如果我们对计数器进行改进，将流程中的第五步移动到第一步之后，即在获取计数器值之后立即更新计数器。这样做确实起到了很大效果，大大减少了“事倍功半”问题出现的概率，但仍然不能彻底解决问题。仍然存在计数器值更新之前 CPU 就将进程切换的可能性。

![new-count](index.assets/new-count.png)

#### 原子操作与临界区

在并发编程中，多个进程对同一个资源进行访问可能会互相干扰，这种情况被称为竞争条件（race condition）。造成竞争条件的根本原因在于进程在进行某些操作的过程中被中断，虽然进程再次运行时其状态会恢复如初，但是外界环境可能在此时间段内已经发生了改变。在上面改进版的计数器例子中，虽然已经尽可能避免，但由于进程调度的不可控性使得竞态条件仍然可能发生。为了解决这个问题，我们引入**原子操作**与**临界区**这两个概念。

原子操作意为“**执行过程中不可被中断的一个或一系列操作**”，也不允许在执行结束之前被任何任务或者事件终止，要么全部执行，要么就不执行。原子操作必须由一个单一的汇编指令表示，并且需要得到芯片级的支持，因此原子操作线程间交互数据最细粒度的同步操作，它可以保证线程间读写某个数值的原子性，绝对的并发安全。

相比于原子操作，让串行化执行的若干代码形成临界区的做法更加通用。临界区在任意时刻只允许一个线程对共享资源进行访问，从而实现互斥（mutex）。互斥遵循排他原则，如果有多个线程试图同时访问临界区，那么在有一个线程进入后，其他所有试图访问此临界区的线程将被挂起，并一直持续到进入临界区的线程离开。原子操作和临界区看起来类似，但是原子操作不能被中断，临界区对是否能被中断没有强制规定，只要保证一个访问者在临界区中时其他访问者不允许进入。

如果我们把获取更新计数器值的过程形成临界区，进程在执行此操作的过程中不会被打断，其他进程只能在更新值之后再取值，就可以避免竞争条件的发生。

## 线程的设计

利用多进程编程也有一些缺点，例如进程的创建、切换开销比较大，一个进程无法同时执行多个任务等。因此在进程内部引入了更加灵活的线程。线程可视为进程中的控制流，是程序执行的最小单位。线程的衍生过程与进程类似，通过其他线程调用系统调用函数`pthread_create`创建。但与进程的树状结构不同，线程之间是平级的关系，不存在所属关系。

在一个进程内的所有线程共享同一地址空间、文件描述符、栈以及与进程相关的属性。因此创建一个新线程时，不会复制其所属进程中存储的数据、代码等，因此线程更加轻量，开销小很多。另外，每个线程也拥有自己的线程栈，存储一些私有数据。

线程也拥有唯一标识 ID，称为 TID，在 Linux 中 TID 在整个系统范围内具有唯一性。

#### 控制与状态

线程可以对同一进程中的其他线程进行一定的控制，主要有以下四种情况：

- **创建**：线程通过调用系统调用函数`pthread_create`创建新线程，调用线程需要向新线程传入执行函数与参数，创建成功后获得新线程的 TID；
- **终止**：线程调用系统调用函数`pthread_cancel`发送一个请求来终止执行目标线程（也可以是自身），但目标线程不会立即终止，一般情况下线程执行到某个取消点时才会终止；
- **连接**：线程调用`pthread_join` 来连接目标函数，调用函数会获取目标函数的返回值与流程控制权，并继续执行；
- **分离**：线程调用`pthread_detach` 来分离自身或其他线程，被分离的线程在终止时会被内核自动清理和销毁。

线程在生命周期中也会进行一系列状态转换，其过程与进程类似，这里不再过多赘述。

#### 线程调度

系统内核对线程的调度是比较重要的部分，调度器会把时间划分成极小的时间片分配给不同的线程，使得每个线程都有机会在 CPU 上运行。由于线程的执行过程分为 CPU 消耗型或 I/O 消耗型，一些线程需要花费一定的时间使用 CPU 进行计算，而另外一些线程会花费时间等待 I/O 操作，比如等待键盘输入。调度器会对线程进行优先级划分，其中静态优先级决定了线程单次在 CPU 上运行的最长时间，动态优先级则决定了线程的执行顺序。通常情况下调度器会分配给 I/O 消耗型线程更高的优先级，以便于花费更多时间的 I/O 操作尽早执行。

线程的静态优先级是一个常量，如果应用程序没有显示指定其值，默认设定为 0。动态优先级在静态优先级的基础上得来，而且可以被调度器实时调整。所有等待 CPU 的线程按照动态优先级从高到低的顺序排列，放到 CPU 对应的运行队列中，因此下一个运行的线程总是动态优先级中最高的一个。优先级阵列是一个由链表组成的数组，一个链表中只包含具有相同优先级的线程，新加入的线程会被放到对应链表的末尾处。实际上，每一个 CPU 的运行队列中包含两个优先级阵列，其中一个存放正在等待运行的线程，另一个存放已经运行过但还未完成的线程。

#### 线程的实现模型



## 线程的同步

## 总结



## Reference

- [还在疑惑并发和并行？](https://laike9m.com/blog/huan-zai-yi-huo-bing-fa-he-bing-xing,61/)
- [进程管理](http://wuchong.me/blog/2014/07/24/linux-process-manage/)
- [Linux 进程状态解析](https://blog.csdn.net/wudebao5220150/article/details/12919453)
- [anatomy-of-a-program-in-memory](https://manybutfinite.com/post/anatomy-of-a-program-in-memory/)
- [深入 Linux 的进程优先级](https://linux.cn/article-7325-1.html)